---
title: "An Ensemble Model to Predict Maternal Health Risk Levels"
author: "Gakhar, Mallika"
date: "2024-12-04"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
  pdf_document:
    toc: true
subtitle: DA5030
---

## Introduction

This project's main objective is to create and assess machine learning models that use clinical measures to forecast the maternal health risk level (low, medium, or high). This is a classification problem because the target variable (RiskLevel) is categorical.

The following steps are the project's main focus:

1. Using exploratory data analysis to comprehend the dataset and spot trends.

2. Classifying maternal health risk levels using a variety of machine learning methods.

3. Improving model performance using ensemble methods like bagging and boosting as well as hyperparameter adjustment.

4. Building a heterogeneous ensemble model to integrate each classifier's unique strengths.

The CRISP-DM technique is followed in this project, which covers every step from business comprehension to model evaluation. This initiative intends to address maternal health issues in line with the Sustainable Development Goals (SDG) of the UN by precisely identifying risk levels and assisting healthcare providers in prompt treatments.

```{r LoadPackages, warning=F}
library(dbplyr)
library(ggplot2)
library(corrplot)
library(class)
library(rpart)
library(e1071)
#if (!require(caret)) install.packages("caret", dependencies = TRUE)
library(lattice)
library(caret)
library(randomForest)
```

## Data Acquisition

The project's dataset was gathered using an Internet of Things-based risk monitoring system from a number of hospitals, community clinics, and maternal health care facilities in rural Bangladesh. Using six features—age, systolic and diastolic blood pressure, blood sugar levels, body temperature, and heart rate—this dataset **focuses on predicting maternal health risk level**.

**Introductory Paper**: Ahmed, Marzia, et al. "Review and Analysis of Risk Factor of Maternal Health in Remote Area Using the Internet of Things (IoT)." Lecture Notes in Electrical Engineering, vol 632, 2020.

The dataset is loaded from a publicly accessible link.

```{r Load data}
url <- "https://drive.google.com/uc?id=1jjiarZs1U5-S8JinX8x4kIjNJxe35X2o&export=download"

df <- read.csv(url, header=TRUE, stringsAsFactors = F)
```

## Data Exploration

### 1. Exploratory Data Analysis and Plots

Before model building, it is crucial to explore the dataset to understand its structure, distribution, and any patterns. This includes the following steps:

```{r EDA}
head(df, 5)
summary(df)
str(df)
dim(df)
```

The dataset contains **1,014 observations** with **7 variables**, including 6 features (`Age`, `SystolicBP`, `DiastolicBP`, `BS`, `BodyTemp`, and `HeartRate`) and one target variable (`RiskLevel`). 

Initial inspection of the data using `head()` shows examples of individuals with varying maternal health risk levels (e.g., "high risk" and "low risk"). 

Summary statistics reveal that key numerical features like `Age`, `SystolicBP`, and `BS` vary widely across the dataset, with no missing values. 

The `str()` output confirms that most features are numeric, while the target variable is categorical, making this dataset well-suited for a **classification analysis**.

```{r EDA_risklevelplot}
# Distribution of RiskLevel
ggplot(df, aes(x = RiskLevel)) +
  geom_bar(fill = "coral") +
  theme_minimal() +
  labs(title = "Distribution of Risk Levels", x = "Risk Level", y = "Count")
```

The majority of data points seem to fall into the "Low Risk" category, which appears to have the largest count. It appears that the distribution is biased in favor of "Low Risk," with "High Risk" having the lowest number.

```{r EDA_AgevsRiskLevelPlot}
# Age distribution across Risk Levels
ggplot(df, aes(x = RiskLevel, y = Age, fill = RiskLevel)) +
  geom_boxplot(outlier.color = "red", outlier.size = 2) +
  theme_minimal() +
  labs(title = "Age Distribution by Risk Level", x = "Risk Level", y = "Age") +
  scale_fill_brewer(palette = "Pastel1")
```

The distribution of ages within a certain risk group is shown by each box plot. The interquartile range (IQR), which includes 50% of the data, is displayed in the box itself. The median age is shown by the line inside the box. With outliers excluded, the whiskers reach the minimum and maximum values. Outliers, or data points that greatly deviate from the range of the majority of the data, are indicated by red dots above the whiskers.

All low and mid risk groups seem to have comparable median ages, with "High Risk" having a little higher median than the other two (around 30+).

There are no notable variations in the IQRs, and the age distribution within each category is rather comparable.

Some outliers are evident, especially in the "Low Risk" group. These anomalies imply that this category has a few uncommon examples.

It might suggest that older individuals are more likely to be categorized as "High Risk." However, the presence of outliers in other categories might indicate that age alone is not the sole determinant of risk.

```{r EDA_}
# Scatter plot of SystolicBP vs. DiastolicBP 
# color is RiskLevel
ggplot(df, aes(x = SystolicBP, y = DiastolicBP, color = RiskLevel)) +
  geom_point(size = 3, alpha = 0.7) +
  theme_minimal() +
  labs(title = "Systolic vs. Diastolic BP by Risk Level", 
       x = "Systolic Blood Pressure", 
       y = "Diastolic Blood Pressure") +
  scale_color_brewer(palette = "Set1")
```

A person's blood pressure is represented by each plot point, and their risk group is shown by the color. Blood pressure may not be a reliable indicator of risk on its own, according to overlapping systolic and diastolic ranges. All categories exhibit clustering in lower pressure ranges, with risk somewhat rising at higher pressures. Outliers signify abnormally high readings, especially at high systolic values.

### 2. Outlier detection

To detect outliers in the dataset, we use the Interquartile Range (IQR) method. This method calculates the IQR as the difference between the 75th percentile (Q3) and the 25th percentile (Q1). Any values that fall below `Q1−1.5×IQR` or above `Q3+1.5×IQR` are considered outliers. By applying this technique, we can identify extreme values in continuous variables such as Age, Systolic Blood Pressure, Diastolic Blood Pressure, Blood Sugar, Body Temperature, and Heart Rate.

```{r OutlierDetection}
# Function to detect no. of outliers
outlier_count <- function(df, column) {
  Q1 <- quantile(df[[column]], 0.25)
  Q3 <- quantile(df[[column]], 0.75)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  outliers_count <- sum(df[[column]] < lower_bound | df[[column]] > upper_bound)
  return(outliers_count)
}

# apply function to each column
outliers_count_age <- outlier_count(df, "Age")
outliers_count_systolicBP <- outlier_count(df, "SystolicBP")
outliers_count_diastolicBP <- outlier_count(df, "DiastolicBP")
outliers_count_bs <- outlier_count(df, "BS")
outliers_count_bodyTemp <- outlier_count(df, "BodyTemp")
outliers_count_heartRate <- outlier_count(df, "HeartRate")

# print outliers
cat("Number of outliers in Age: ", outliers_count_age, "\n")
cat("Number of outliers in SystolicBP: ", outliers_count_systolicBP, "\n")
cat("Number of outliers in DiastolicBP: ", outliers_count_diastolicBP, "\n")
cat("Number of outliers in BS: ", outliers_count_bs, "\n")
cat("Number of outliers in BodyTemp: ", outliers_count_bodyTemp, "\n")
cat("Number of outliers in HeartRate: ", outliers_count_heartRate, "\n")
```

**Understanding Outliers** - The dataset contains outliers across several columns. For Age, only one outlier is present, which may not require attention unless it significantly deviates from the rest of the data. SystolicBP has 10 outliers, potentially reflecting extreme values due to either incorrect measurements or patients with abnormal conditions. Blood Sugar (BS) and Body Temperature each have 210 outliers, which may indicate erroneous data points or anomalies such as medical conditions like diabetes. Finally, Heart Rate has two outliers, which are few but still worth reviewing.

### 3. Correlation/collinearity/chi-squared analysis

In this step, we will calculate the correlation between the continuous variables to understand the relationships between them. Strong correlations between features may indicate multicollinearity, which can affect model performance by making it harder to determine the individual effect of each feature. We will also assess the potential for collinearity by checking the correlation values. If high correlations (above 0.6 or below -0.6) are found, we may consider removing or combining some of the correlated features to avoid redundant information.

A chi-squared test is used to assess whether there is a significant association between two categorical variables. Here, RiskLevel is categorical, but the features are continuous. Since the chi-square test requires both variables to be categorical, it is not suitable for analyzing the relationship between continuous features and a categorical target.

```{r CorrleationAnalysis}
# continuous variables for corr analysis
continuous_vars <- df[, c("Age", "SystolicBP", "DiastolicBP", "BS", "BodyTemp", "HeartRate")]

# build correlation matrix
corr_matrix <- cor(continuous_vars)
print(corr_matrix)

# view
corrplot(corr_matrix, method = "circle", type = "upper", tl.col = "black")
```

**Correlation Observations:**

* Systolic blood pressure and age have a somewhat favorable connection (0.416). Systolic blood pressure tends to rise with age, albeit not significantly.

* Diastolic and systolic blood pressure have a substantial positive connection (0.787). This implies that diastolic blood pressure is often higher in those with higher systolic blood pressure.

* The BS and systolic blood pressure have a moderately positive connection (0.425). Blood Sugar (BS) has the tendency to rise in tandem with an increase in Systolic Blood Pressure.

* There is a moderately favorable connection between age and BS (0.473). Blood sugar levels are often greater in older people.

* Heart rate and body temperature have a very small positive connection (0.099). The poor correlation between body temperature and heart rate suggests that variations in body temperature have little effect on heart rate.

* Systolic blood pressure (-0.287) and body temperature have a weakly negative connection. Although this association is modest, systolic blood pressure tends to slightly fall when body temperature rises.

**Correlation Interpretation**

Because of their great correlation, systolic and diastolic blood pressure may be removed from predictive models because of collinearity. Age may be a significant predictor of both BS and SystolicBP, as seen by the moderate correlations between the two variables. Furthermore, there are minor correlations between Body Temperature and Heart Rate and the other features, suggesting that they have minimal influence on the relationships among the other variables in the dataset.

### 4. Evaluation of distribution

To evaluate the distribution of continuous variables we can use histograms and the Shapiro-Wilk test. Histograms visually show whether the data is symmetric, skewed, or multimodal. The Shapiro-Wilk test statistically tests normality, with p-values less than 0.05 indicating a non-normal distribution.

Choosing the right statistical techniques requires evaluating the distribution. While skewed or outlier-containing data may necessitate non-parametric techniques or modifications, normally distributed data permits parametric testing.

```{r DistributionEvaluation}
# Shapiro-Wilk test for normality for each col
shapiro_test_results <- sapply(df[, -7], function(x) shapiro.test(x)$p.value)

# view
cat("Shapiro-Wilk Test Results for Normality:\n")
print(shapiro_test_results)
```

**Shapiro-Wilk Test Result Interpretation** - The Shapiro-Wilk test results show that the p-values for all columns are extremely small (well below the commonly used significance threshold of 0.05). This indicates that the null hypothesis of normality is rejected for all variables. In other words, none of the features in the dataset are normally distributed. The low p-values suggest that these variables deviate significantly from a normal distribution.

```{r DistributionGraphs}
# histogram for 'Age'
ggplot(df, aes(x = Age)) +
  geom_histogram(bins = 20, fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Age", x = "Age", y = "Frequency")

# histogram for 'BS' (Blood Sugar)
ggplot(df, aes(x = BS)) +
  geom_histogram(bins = 20, fill = "lightgreen", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Blood Sugar (BS)", x = "Blood Sugar (BS)", y = "Frequency")

# histogram for 'HeartRate'
ggplot(df, aes(x = HeartRate)) +
  geom_histogram(bins = 20, fill = "lightcoral", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Heart Rate", x = "Heart Rate", y = "Frequency")
```

It can be confirmed from the above graphs, that the data is indeed not distributed normally but skewed. 

## Data Cleaning and Shaping

### 1. Identification of Missing Values

```{r CheckMissingvalues}
# Check for missing values
missing_values <- colSums(is.na(df))

# view missing values per col
print(missing_values)
```

### 2. Data Imputation of Missing data

Since there aren't any missing values, we can remove data from a few rows at random to mimic missing data. This will illustrate the impact of imputing missing values on algorithm performance.

How to Make a New Dataset with Data Removed at Random:

* Randomly remove data: A tiny percentage of the dataset may have data removed at random.

* Impute the missing values: To produce a different dataset, we will next impute the missing values.

* Compare the performance: Afterwards, we can assess and contrast how well the algorithms perform on the dataset that contains imputed data with the dataset as a whole.

```{r DataImputationSimulation}
set.seed(123) 

# Randomly remove 10% of data from each column
# dont include target variable 
random_missing <- function(df, target_col, missing_percentage = 0.1) {
  df_copy <- df
  for (col in colnames(df_copy)) {
    # Skip the target col
    if (col != target_col) {
      missing_indices <- sample(1:nrow(df_copy), size = floor(missing_percentage * nrow(df_copy)), replace = FALSE)
      df_copy[missing_indices, col] <- NA
    }
  }
  return(df_copy)
}

# df randomly missing values
target_column <- "RiskLevel"
simulated_df <- random_missing(df, target_column, missing_percentage = 0.1)

# Check for missing val after removal
cat("Missing values after random removal:\n")
print(colSums(is.na(simulated_df)))

# Impute missing values for all col using mean
for (col in colnames(simulated_df)) {
  if (is.numeric(simulated_df[[col]]) && col != target_column) {
    # Replace NA values with the mean of each col
    simulated_df[[col]][is.na(simulated_df[[col]])] <- mean(simulated_df[[col]], na.rm = TRUE)
  }
}

# Check
cat("Missing values after imputation:\n")
print(colSums(is.na(simulated_df)))
```

### 3. Normalization/Standardization of Feature Values

We will use the same normalization technique to both the simulated dataset (simulated_df) and the original dataset (df) in order to complete the normalization phase following the data imputation procedure.

We chose normalization (min-max scaling) over standardization (z-score normalization) since the dataset contains characteristics that are not normally distributed (based on the findings of the Shapiro-Wilk test). This approach scales the values to a specific range (typically [0, 1]), and it doesn't assume normality. It is more appropriate for features that may have different distributions but should be compared on a common scale.

```{r FeatureNormalization}
# Normalize function (Min-Max norm)
normalize <- function(x) {
  if (length(unique(x)) == 1) {
    return(rep(NA, length(x)))  # Return NA for constant columns
  }
  return((x - min(x)) / (max(x) - min(x)))
}

# Identify numeric col
numerical_columns_df <- sapply(df, is.numeric)
numerical_columns_df <- numerical_columns_df & !(names(df) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))

# Apply normalization 
df_normalized <- df
df_normalized[numerical_columns_df] <- lapply(df_normalized[numerical_columns_df], normalize)

# View
cat("Normalized Original Data (df):\n")
head(df_normalized)
```

```{r FeatureNormalization_Simulation}
# Normalize function
normalize <- function(x) {
  if (length(unique(x)) == 1) {
    return(rep(NA, length(x)))  # Return NA for constant columns
  }
  return((x - min(x)) / (max(x) - min(x)))
}

# Identify numeric col
numerical_columns_simulated <- sapply(simulated_df, is.numeric)
numerical_columns_simulated <- numerical_columns_simulated & !(names(simulated_df) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))

# Apply normalization
simulated_df_normalized <- simulated_df
simulated_df_normalized[numerical_columns_simulated] <- lapply(simulated_df_normalized[numerical_columns_simulated], normalize)

# View
cat("Normalized Simulated Data (simulated_df):\n")
head(simulated_df_normalized)
```

### 4. Encoding if Required for Algorithm

Since the target variable, RiskLevel, has three levels (e.g., "high risk", "low risk", and "medium risk"), it is necessary to encode it properly for machine learning models. One-hot encoding is the appropriate approach in this case, as it will create separate binary columns for each category, avoiding any assumption of an ordinal relationship (e.g., "low risk" < "medium risk" < "high risk").

**Explanation:** `model.matrix(~ RiskLevel - 1, data = simulated_df_encoded)` generates the one-hot encoded columns for the RiskLevel column. The `- 1` ensures that no intercept is added to the model matrix. `df_encoded$RiskLevel <- NULL` removes the original categorical RiskLevel column from the dataset since it has been replaced with the one-hot encoded columns. The new column names are then replaced for consistency.

```{r OneHotEncoding_orignal}
# One-hot encoding using model.matrix() in base R
df_encoded <- df_normalized
df_encoded <- cbind(df_encoded, model.matrix(~ RiskLevel - 1, data = df_encoded))  # One-hot encoding
df_encoded$RiskLevel <- NULL  # Remove the orignal col

# Rename col
colnames(df_encoded)[which(colnames(df_encoded) == "RiskLevelhigh risk")] <- "RiskLevel_high"
colnames(df_encoded)[which(colnames(df_encoded) == "RiskLevellow risk")] <- "RiskLevel_low"
colnames(df_encoded)[which(colnames(df_encoded) == "RiskLevelmid risk")] <- "RiskLevel_mid"
```

Now we do the same for the simulated data frame.

```{r Encoding_simulateddf}
# One-hot encoding using model.matrix() in base R for simulated_df
simulated_df_encoded <- simulated_df_normalized
simulated_df_encoded <- cbind(simulated_df_encoded, model.matrix(~ RiskLevel - 1, data = simulated_df_encoded))  # One-hot encoding
simulated_df_encoded$RiskLevel <- NULL  # Remove the original col

# Rename col
colnames(simulated_df_encoded)[which(colnames(simulated_df_encoded) == "RiskLevelhigh risk")] <- "RiskLevel_high"
colnames(simulated_df_encoded)[which(colnames(simulated_df_encoded) == "RiskLevellow risk")] <- "RiskLevel_low"
colnames(simulated_df_encoded)[which(colnames(simulated_df_encoded) == "RiskLevelmid risk")] <- "RiskLevel_mid"

# check
head(simulated_df_encoded, 3)
```

### 5. Transformation of features to adjust distribution

Since the data is not normally distributed, I tried log transformation but from the Shapiro-Wilk test results after transformation revealed that even after transformation, the data was not normally distributed. Hence, I decided to move ahead with original and simulated normalized dataframe i.e. which has not been transformed. 

```{r LogTransformation}
# Log Transformation
log_transform <- function(df, columns) {
  df_copy <- df
  for (col in columns) {
    df_copy[[col]] <- log(df_copy[[col]] + 1)  # Adding 1 to avoid log(0)
  }
  return(df_copy)
}

# Apply transformations
numeric_columns <- c("Age", "SystolicBP", "DiastolicBP", "BS", "BodyTemp", "HeartRate")

# For df
df_transformed <- log_transform(df_encoded, numeric_columns)

# Check
head(df_transformed, 3)

# Perform Shapiro-Wilk test for each col in transformed data
shapiro_results_df <- data.frame(
  Column = numeric_columns,
  W_Value = sapply(df_transformed[numeric_columns], function(x) shapiro.test(x)$statistic),
  P_Value = sapply(df_transformed[numeric_columns], function(x) shapiro.test(x)$p.value)
)

# view
cat("Shapiro-Wilk test results for Transformed Original Data (df):\n")
print(shapiro_results_df)
```

### 6. Identification of PCA

By reducing high-dimensional data to a smaller set of uncorrelated variables known as principal components, PCA is a dimensionality reduction approach that can assist in locating the underlying structure in the data.

```{r PCA}
# Perform PCA for df
pca_df <- prcomp(df_encoded, center = TRUE, scale. = TRUE)

# Print summary of PCA
cat("PCA Summary for Original Dataset:\n")
summary(pca_df)

# Scree plot to visualize variance explained
cat("\nScree Plot for Original Dataset:\n")
plot(pca_df, type = "l", main = "Scree Plot for Original Dataset")
```
**PCA Summary for Original Dataset:**

* Variance Explained: The first three components account for more than 69% of the variance, with PC1 capturing 35.08%, PC2 contributing 18.43%, and PC3 contributing 15.82%. PC4 accounts for 79.63% of the variance, with subsequent components making up a negligible portion.

* The Scree Plot confirms that PC1–PC3 capture the majority of the variance by displaying a steep decline after the first few components.
Meaning, with just six features, PCA provides little value.

* PCA doesn't substantially reduce complexity because the dataset is already low-dimensional.
By altering original features, which are crucial for analysis, PCA lessens interpretability.

* The efficiency of PCA is limited by low feature correlation.

In conclusion, this dataset does not require PCA. For improved interpretability in subsequent analysis, the original characteristics will be utilized.

### 7. Feature Engineering: New Derived Features

In order to improve model performance or uncover hidden patterns, feature engineering entails generating new features from preexisting ones. Among the examples are:

* A feature combining SystolicBP × DiastolicBP to capture their interaction.

* Binning age into categories instead of using it as a continuous variable.

* Deriving a feature indicating blood pressure levels (e.g., normal, elevated, high) based on SystolicBP and DiastolicBP.

While these are viable options, I decided not to add them as I felt they would not improve the model.

## Model Construction

### 1. Creation of Training and Validation Subsets

```{r DataSplit}
set.seed(123)

# Split the original encoded dataset (df_encoded)
split_indices_df <- sample(1:nrow(df_encoded), size = 0.8 * nrow(df_encoded))
df_encoded_train <- df_encoded[split_indices_df, ]
df_encoded_test <- df_encoded[-split_indices_df, ]

# check dim
cat("Original Dataset (df_encoded):\n")
cat("Training Set Dimensions:", dim(df_encoded_train), "\n")
cat("Testing Set Dimensions:", dim(df_encoded_test), "\n\n")

# Split simulated encoded df (simulated_df_encoded)
split_indices_simulated <- sample(1:nrow(simulated_df_encoded), size = 0.8 * nrow(simulated_df_encoded))
simulated_df_encoded_train <- simulated_df_encoded[split_indices_simulated, ]
simulated_df_encoded_test <- simulated_df_encoded[-split_indices_simulated, ]

# chcek dim
cat("Simulated Dataset (simulated_df_encoded):\n")
cat("Training Set Dimensions:", dim(simulated_df_encoded_train), "\n")
cat("Testing Set Dimensions:", dim(simulated_df_encoded_test), "\n")
```

### 2. Creation of Model A with proper data encoding: k-Nearest Neighbors (kNN)

```{r kNN_orignalDF}
set.seed(123)

# kNN for df_encoded
df_encoded_train_features <- df_encoded_train[, -which(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
df_encoded_train_labels <- apply(df_encoded_train[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)

df_encoded_test_features <- df_encoded_test[, -which(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
df_encoded_test_labels <- apply(df_encoded_test[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)

k <- 5
knn_pred_df <- knn(train = df_encoded_train_features, test = df_encoded_test_features, cl = df_encoded_train_labels, k = k)
knn_accuracy_df <- sum(knn_pred_df == df_encoded_test_labels) / length(df_encoded_test_labels)
cat("kNN Accuracy for df_encoded:", knn_accuracy_df, "\n")
```

```{r kNN_orignalDF_eval}
# Confusion Matrix for df_encoded
confusion_matrix_df <- table(Predicted = knn_pred_df, Actual = df_encoded_test_labels)
cat("Confusion Matrix for df_encoded:\n")
print(confusion_matrix_df)

# Precision
precision_df <- sum(knn_pred_df == 1 & df_encoded_test_labels == 1) / sum(knn_pred_df == 1)

# recall
recall_df <- sum(knn_pred_df == 1 & df_encoded_test_labels == 1) / sum(df_encoded_test_labels == 1)

# f1_score
f1_score_df <- 2 * (precision_df * recall_df) / (precision_df + recall_df)

cat("Precision for df_encoded:", precision_df, "\n")
cat("Recall for df_encoded:", recall_df, "\n")
cat("F1-Score for df_encoded:", f1_score_df, "\n")
```

```{r kNN_simulatedDF}
# kNN for simulated_df_encoded
simulated_df_train_features <- simulated_df_encoded_train[, -which(names(simulated_df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
simulated_df_train_labels <- apply(simulated_df_encoded_train[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)

simulated_df_test_features <- simulated_df_encoded_test[, -which(names(simulated_df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
simulated_df_test_labels <- apply(simulated_df_encoded_test[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)

knn_pred_simulated <- knn(train = simulated_df_train_features, test = simulated_df_test_features, cl = simulated_df_train_labels, k = k)
knn_accuracy_simulated <- sum(knn_pred_simulated == simulated_df_test_labels) / length(simulated_df_test_labels)
cat("kNN Accuracy for simulated_df_encoded:", knn_accuracy_simulated, "\n")
```

```{r kNN_simulatedDF_eval}
# Confusion Matrix for simulated_df_encoded
confusion_matrix_simulated <- table(Predicted = knn_pred_simulated, Actual = simulated_df_test_labels)
cat("Confusion Matrix for simulated_df_encoded:\n")
print(confusion_matrix_simulated)

# Precision, Recall, and F1-Score for simulated_df_encoded
precision_simulated <- sum(knn_pred_simulated == 1 & simulated_df_test_labels == 1) / sum(knn_pred_simulated == 1)

# recall
recall_simulated <- sum(knn_pred_simulated == 1 & simulated_df_test_labels == 1) / sum(simulated_df_test_labels == 1)

# f-1 score
f1_score_simulated <- 2 * (precision_simulated * recall_simulated) / (precision_simulated + recall_simulated)

cat("Precision for simulated_df_encoded:", precision_simulated, "\n")
cat("Recall for simulated_df_encoded:", recall_simulated, "\n")
cat("F1-Score for simulated_df_encoded:", f1_score_simulated, "\n")
```

**Evaluation:** The accuracy of the kNN model for the original dataset (df_encoded) was 70.94%. With an F1-score of 0.82, a precision of 0.90, and a recall of 0.75, the confusion matrix performs reasonably well in categorization. In comparison to the actual dataset, the model's accuracy for the simulated dataset (simulated_df_encoded) was 69.46%, with somewhat lower precision (0.84), recall (0.75), and F1-score (0.79). The measures reveal that the two datasets performed similarly, with the original dataset having a small advantage.

### 3. Creation of Model B with proper data encoding: Decision Trees

```{r DT_orginalDF_model}
# data
df_encoded_train$RiskLevel <- as.factor(apply(df_encoded_train[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))
df_encoded_test$RiskLevel <- as.factor(apply(df_encoded_test[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))

# model
decision_tree_model_df_encoded <- rpart(RiskLevel ~ ., data = df_encoded_train[, !(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))])

decision_tree_pred_df_encoded <- predict(decision_tree_model_df_encoded, df_encoded_test[, !(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))], type = "class")

# accuracy
decision_tree_accuracy_df_encoded <- sum(decision_tree_pred_df_encoded == df_encoded_test$RiskLevel) / length(df_encoded_test$RiskLevel)
cat("Decision Tree Accuracy for df_encoded:", decision_tree_accuracy_df_encoded, "\n")

```

```{r DT_orignalDF_eval}
# Confusion Matrix for df_encoded
confusion_matrix_df_encoded_dt <- table(Predicted = decision_tree_pred_df_encoded, Actual = df_encoded_test$RiskLevel)
cat("Confusion Matrix for df_encoded (Decision Tree):\n")
print(confusion_matrix_df_encoded_dt)

# Precision
precision_df_encoded_dt <- sum(decision_tree_pred_df_encoded == 1 & df_encoded_test$RiskLevel == 1) / sum(decision_tree_pred_df_encoded == 1)

# recall
recall_df_encoded_dt <- sum(decision_tree_pred_df_encoded == 1 & df_encoded_test$RiskLevel == 1) / sum(df_encoded_test$RiskLevel == 1)

# f-1 score
f1_score_df_encoded_dt <- 2 * (precision_df_encoded_dt * recall_df_encoded_dt) / (precision_df_encoded_dt + recall_df_encoded_dt)

cat("Precision for df_encoded (Decision Tree):", precision_df_encoded_dt, "\n")
cat("Recall for df_encoded (Decision Tree):", recall_df_encoded_dt, "\n")
cat("F1-Score for df_encoded (Decision Tree):", f1_score_df_encoded_dt, "\n")
```

```{r DT_simulatedDF}
# Decision Tree for simulated_df_encoded
simulated_df_encoded_train$RiskLevel <- as.factor(apply(simulated_df_encoded_train[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))
simulated_df_encoded_test$RiskLevel <- as.factor(apply(simulated_df_encoded_test[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))

decision_tree_model_simulated_df_encoded <- rpart(RiskLevel ~ ., data = simulated_df_encoded_train[, !(names(simulated_df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))])
decision_tree_pred_simulated_df_encoded <- predict(decision_tree_model_simulated_df_encoded, simulated_df_encoded_test[, !(names(simulated_df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))], type = "class")

# accuracy
decision_tree_accuracy_simulated_df_encoded <- sum(decision_tree_pred_simulated_df_encoded == simulated_df_encoded_test$RiskLevel) / length(simulated_df_encoded_test$RiskLevel)
cat("Decision Tree Accuracy for simulated_df_encoded:", decision_tree_accuracy_simulated_df_encoded, "\n")
```

```{r DT_simaultedDF_eval}
# Confusion Matrix for simulated_df_encoded
confusion_matrix_simulated_df_encoded_dt <- table(Predicted = decision_tree_pred_simulated_df_encoded, Actual = simulated_df_encoded_test$RiskLevel)
cat("Confusion Matrix for simulated_df_encoded (Decision Tree):\n")
print(confusion_matrix_simulated_df_encoded_dt)

# Precision
precision_simulated_df_encoded_dt <- sum(decision_tree_pred_simulated_df_encoded == 1 & simulated_df_encoded_test$RiskLevel == 1) / sum(decision_tree_pred_simulated_df_encoded == 1)

# recall
recall_simulated_df_encoded_dt <- sum(decision_tree_pred_simulated_df_encoded == 1 & simulated_df_encoded_test$RiskLevel == 1) / sum(simulated_df_encoded_test$RiskLevel == 1)

# f1 score
f1_score_simulated_df_encoded_dt <- 2 * (precision_simulated_df_encoded_dt * recall_simulated_df_encoded_dt) / (precision_simulated_df_encoded_dt + recall_simulated_df_encoded_dt)

cat("Precision for simulated_df_encoded (Decision Tree):", precision_simulated_df_encoded_dt, "\n")
cat("Recall for simulated_df_encoded (Decision Tree):", recall_simulated_df_encoded_dt, "\n")
cat("F1-Score for simulated_df_encoded (Decision Tree):", f1_score_simulated_df_encoded_dt, "\n")
```

**Evaluation**: The decision tree model's accuracy for the original dataset (df_encoded) was 66.50%. An F1-score of 0.75, recall of 0.78, and precision of 0.73 are displayed in the confusion matrix. At 67.49% accuracy, the model did marginally better for the simulated dataset (simulated_df_encoded). In comparison to the original dataset, precision rose to 0.84, recall to 0.78, and the F1-score to 0.81. On the simulated dataset, the decision tree model performed better overall, especially in terms of precision and F1-score.


### 4. Creation of Model C with proper data encoding: Support Vector Machine (SVM)

```{r SVM_orignalDF}
# SVM for df_encoded
svm_model_df_encoded <- svm(
  RiskLevel ~ .,
  data = df_encoded_train[, !(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))],
  kernel = "radial",
  cost = 1,
  probability = TRUE
)

svm_pred_df_encoded <- predict(svm_model_df_encoded, df_encoded_test[, !(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))])
svm_accuracy_df_encoded <- sum(svm_pred_df_encoded == df_encoded_test$RiskLevel) / length(df_encoded_test$RiskLevel)
cat("SVM Accuracy for df_encoded:", svm_accuracy_df_encoded, "\n")

```

```{r SVM_orignalDF_eval}
# Confusion Matrix for df_encoded
confusion_matrix_df_encoded_svm <- table(Predicted = svm_pred_df_encoded, Actual = df_encoded_test$RiskLevel)
cat("Confusion Matrix for df_encoded (SVM):\n")
print(confusion_matrix_df_encoded_svm)

# Precision
precision_df_encoded_svm <- sum(svm_pred_df_encoded == 1 & df_encoded_test$RiskLevel == 1) / sum(svm_pred_df_encoded == 1)

# recall
recall_df_encoded_svm <- sum(svm_pred_df_encoded == 1 & df_encoded_test$RiskLevel == 1) / sum(df_encoded_test$RiskLevel == 1)

# f1-score
f1_score_df_encoded_svm <- 2 * (precision_df_encoded_svm * recall_df_encoded_svm) / (precision_df_encoded_svm + recall_df_encoded_svm)

cat("Precision for df_encoded (SVM):", precision_df_encoded_svm, "\n")
cat("Recall for df_encoded (SVM):", recall_df_encoded_svm, "\n")
cat("F1-Score for df_encoded (SVM):", f1_score_df_encoded_svm, "\n")
```

```{r SVM_simulatedDF}
# SVM for simulated_df_encoded
svm_model_simulated_df_encoded <- svm(
  RiskLevel ~ .,
  data = simulated_df_encoded_train[, !(names(simulated_df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))],
  kernel = "radial",
  cost = 1,
  probability = TRUE
)

svm_pred_simulated_df_encoded <- predict(svm_model_simulated_df_encoded, simulated_df_encoded_test[, !(names(simulated_df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))])

# accuracy
svm_accuracy_simulated_df_encoded <- sum(svm_pred_simulated_df_encoded == simulated_df_encoded_test$RiskLevel) / length(simulated_df_encoded_test$RiskLevel)
cat("SVM Accuracy for simulated_df_encoded:", svm_accuracy_simulated_df_encoded, "\n")

```

```{r SVM_simulatedDF_eval}
# Confusion Matrix for simulated_df_encoded
confusion_matrix_simulated_df_encoded_svm <- table(Predicted = svm_pred_simulated_df_encoded, Actual = simulated_df_encoded_test$RiskLevel)
cat("Confusion Matrix for simulated_df_encoded (SVM):\n")
print(confusion_matrix_simulated_df_encoded_svm)

# Precision
precision_simulated_df_encoded_svm <- sum(svm_pred_simulated_df_encoded == 1 & simulated_df_encoded_test$RiskLevel == 1) / sum(svm_pred_simulated_df_encoded == 1)

# recall
recall_simulated_df_encoded_svm <- sum(svm_pred_simulated_df_encoded == 1 & simulated_df_encoded_test$RiskLevel == 1) / sum(simulated_df_encoded_test$RiskLevel == 1)

# f1 score
f1_score_simulated_df_encoded_svm <- 2 * (precision_simulated_df_encoded_svm * recall_simulated_df_encoded_svm) / (precision_simulated_df_encoded_svm + recall_simulated_df_encoded_svm)

cat("Precision for simulated_df_encoded (SVM):", precision_simulated_df_encoded_svm, "\n")
cat("Recall for simulated_df_encoded (SVM):", recall_simulated_df_encoded_svm, "\n")
cat("F1-Score for simulated_df_encoded (SVM):", f1_score_simulated_df_encoded_svm, "\n")
```

**Evaluation:** The SVM model's accuracy for the original dataset (df_encoded) was 70.94%. An F1-score of 0.81, recall of 0.78, and precision of 0.83 are displayed in the confusion matrix. The model's accuracy decreased to 69.46% for the simulated dataset (simulated_df_encoded), with an F1-score of 0.81, precision of 0.86, and recall of 0.76. Although the SVM model's precision on the simulated dataset was marginally higher, the two datasets' overall performance metrics (precision, recall, and F1-score) were quite comparable.

### 5. Appropiateness of Chosen Models for given data

**1. k-Nearest Neighbors (kNN)** - Because it works well with the dataset, the k-Nearest Neighbors (kNN) technique was selected for this model. Because it depends on distance computations, it works well with normalized features and makes sure that feature scales don't unduly affect the outcomes. Since kNN is non-parametric and does not presume a normal distribution, it is adaptable and suitable for a wide range of data kinds. It is also the best option for determining distances and finding patterns in the dataset because to its effective handling of continuous characteristics.

**2. Decision Trees** - Because of its adaptability and suitability for classification tasks, the decision tree method was chosen for this model. It is non-parametric and independent of any particular data distribution, just like kNN. It works well for modeling intricate interactions between characteristics and the target variable since it is resilient to non-linearity. Additionally, it is a great option for classification problems due to its ability to handle a categorical target.

**3. Support Vector Machine** - The Support Vector Machine (SVM) technique was selected because to its efficacy in classification tasks, especially when handling non-linear data using a kernel such as the radial basis function. By employing hyperplanes to separate data, SVM performs well with continuous features and is resilient to different distributions. Additionally, as SVM uses distance-based computations for classification, normalized data improves its performance.

**Why I didn't choose other algorithms?** Since the target variable in this case is categorical, linear and multiple regression are inappropriate because they are made for continuous target variables. Likewise, regularization methods designed for regression tasks, such as Lasso and Ridge regression, are not suitable for classification challenges. Despite their strength, neural networks need large datasets to generalize well, and they are superfluous for datasets with just 1,014 rows; instead, simpler methods like SVM or decision trees function better.

## Model Evaluation

### 1. Evaluation of fit of models with holdout method

I have tried hold-out method to evaluate my kNN model by holding out 10% of the orignal encoded and normalized data to check the model's fit.

```{r Model Evaluation}
set.seed(123)

# Split the df_encoded into 90% training and 10% testing (holdout)
sample_index <- sample(1:nrow(df_encoded), size = 0.9 * nrow(df_encoded))
df_encoded_train_holdout <- df_encoded[sample_index, ]
df_encoded_test_holdout <- df_encoded[-sample_index, ]

# Separate features and labels
df_encoded_train_features <- df_encoded_train_holdout[, -which(names(df_encoded_train_holdout) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
df_encoded_train_labels <- apply(df_encoded_train_holdout[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)

df_encoded_test_features <- df_encoded_test_holdout[, -which(names(df_encoded_test_holdout) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
df_encoded_test_labels <- apply(df_encoded_test_holdout[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)

# Train kNN
k <- 5
knn_pred_holdout <- knn(train = df_encoded_train_features, test = df_encoded_test_features, cl = df_encoded_train_labels, k = k)

# Accuracy
knn_accuracy_holdout <- sum(knn_pred_holdout == df_encoded_test_labels) / length(df_encoded_test_labels)
cat("kNN Accuracy (10% Holdout) for df_encoded:", knn_accuracy_holdout, "\n")

# Confusion Matrix
confusion_matrix_knn_holdout <- table(Predicted = knn_pred_holdout, Actual = df_encoded_test_labels)
cat("Confusion Matrix for kNN (df_encoded) with 10% holdout:\n")
print(confusion_matrix_knn_holdout)

# Precision 
precision_knn_holdout <- sum(knn_pred_holdout == 1 & df_encoded_test_labels == 1) / sum(knn_pred_holdout == 1)
cat("Precision for kNN (df_encoded) with 10% holdout:", precision_knn_holdout, "\n")

# Recall
recall_knn_holdout <- sum(knn_pred_holdout == 1 & df_encoded_test_labels == 1) / sum(df_encoded_test_labels == 1)
cat("Recall for kNN (df_encoded) with 10% holdout:", recall_knn_holdout, "\n")

# F1-Score
f1_score_knn_holdout <- 2 * (precision_knn_holdout * recall_knn_holdout) / (precision_knn_holdout + recall_knn_holdout)
cat("F1-Score for kNN (df_encoded) with 10% holdout:", f1_score_knn_holdout, "\n")
```

**Interpetation:** The accuracy of the kNN model assessed using the 10% holdout approach was 67.65%, which was marginally less than the accuracy of the original model, which was 70.94%. In contrast to the original model's precision of 0.90, recall of 0.75, and F1-score of 0.82, the holdout set displayed precision of 0.94, recall of 0.76, and F1-score of 0.84. While the high precision indicates minimal false positives, the minor decline in accuracy points to the model's sensitivity to changes in the data. The balanced F1-score indicates that the model performs well overall, with little overfitting or underfitting, and the recall suggests a respectable level of efficacy in catching positive cases.

### 2. Evaluation with k-fold cross-validation

```{r KfoldCrossValidation}
# no. of folds
k_folds <- 10

# Create k-fold cross-val indices
folds <- createFolds(df_encoded$RiskLevel_high, k = k_folds, list = TRUE)

# Initialize vector to store accuracy for each fold
accuracy <- c()

# Loop through each fold
for(i in 1:k_folds) {
  
  # Create training and testing df
  train_index <- folds[[i]]
  train_data <- df_encoded[train_index, ]
  test_data <- df_encoded[-train_index, ]
  
  # Separate features and labels
  train_features <- train_data[, -which(names(train_data) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
  train_labels <- apply(train_data[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)
  
  test_features <- test_data[, -which(names(test_data) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
  test_labels <- apply(test_data[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)
  
  # Train kNN model
  k <- 5
  knn_pred <- knn(train = train_features, test = test_features, cl = train_labels, k = k)
  
  # accuracy
  accuracy_fold <- sum(knn_pred == test_labels) / length(test_labels)
  
  # save
  accuracy <- c(accuracy, accuracy_fold)
}

# view
mean_accuracy <- mean(accuracy)
cat("Average Accuracy from k-fold Cross-validation for kNN:", mean_accuracy, "\n")
```

**Interpretation:** For small datasets like mine, k-fold cross-validation might not be as critical, even if it is generally important for assessing model performance, particularly with smaller datasets where it helps minimize overfitting and ensures a more trustworthy performance estimate. The k-fold cross-validation in this instance produced a lower average accuracy of ~59%, indicating that the model's performance varies significantly amongst folds. The holdout technique might offer a good enough estimate of model performance without the extra computational expense of k-fold cross-validation. Consequently, k-fold cross-validation may not be as important for this particular dataset, even though it is still useful for evaluating model stability.

### 3. Tuning of hyperparameters as available

#### 3.1 Tuning of hyperparameters for kNN Model on Orignal Dataset

For the kNN model, following parameters can be tuned:

* Number of neighbors (k)

* Distance metric (e.g., Euclidean, Manhattan)

Here, I have tried to tune the k parameter, which determines the number of neighbors to consider.

```{r HyperParameterTuning_kNN}
# k values for tuning
k_values <- seq(1, 15, by = 2)

# empty vector to store accuracy for each k
accuracy_k_values <- c()

# Loop
for(k in k_values) {
  
  # Train the kNN model on training data with current value of k
  knn_pred_df <- knn(train = df_encoded_train_features, test = df_encoded_test_features, cl = df_encoded_train_labels, k = k)
  
  # accuracy
  knn_accuracy_df <- sum(knn_pred_df == df_encoded_test_labels) / length(df_encoded_test_labels)
  
  # Store accuracy
  accuracy_k_values <- c(accuracy_k_values, knn_accuracy_df)
}

# best k
best_k <- k_values[which.max(accuracy_k_values)]
best_accuracy <- max(accuracy_k_values)

cat("Best k for kNN:", best_k, "\n")
cat("Best Accuracy for kNN:", best_accuracy, "\n")
```

**Interpretation:** The output illustrates how the kNN model's hyperparameters are adjusted by varying the number of neighbors (k). With an accuracy of 88.23%, the optimal value of k, which produces the highest accuracy, is 1. This indicates that when using the nearest neighbor to categorize data points, the model operates at its best.

#### 3.2 Tuning of hyperparameters for Decision Trees Model on Orignal Dataset

Hyper parameters that can be tuned:

* Maximum depth of the tree (maxdepth)

* Minimum number of samples required to split a node (minsplit)

* Minimum number of samples required at a leaf node (minbucket)

* Criterion for splitting (e.g., Gini index or entropy)

Here, I have tried tune maxdepth and minsplit.

```{r HyperParameterTuning_DT}
# RiskLevel is correctly assigned and converted
df_encoded_train$RiskLevel <- as.factor(apply(df_encoded_train[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))
df_encoded_test$RiskLevel <- as.factor(apply(df_encoded_test[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))

# hyperparameter values to tune
maxdepth_values <- c(5, 10, 15)  # Possible max depths for the tree
minsplit_values <- c(10, 20)    # Possible minimum number of observations in a node

#  store accuracy vector
accuracy_values <- c()

# Loop
for(maxdepth in maxdepth_values) {
  for(minsplit in minsplit_values) {
    
    # Train the decision tree model
    decision_tree_model <- rpart(RiskLevel ~ ., 
                                 data = df_encoded_train[, !(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))], 
                                 control = rpart.control(maxdepth = maxdepth, minsplit = minsplit))
    
    # Make predictions on the test set
    decision_tree_pred <- predict(decision_tree_model, df_encoded_test[, !(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))], type = "class")
    
    # Calculate accuracy
    accuracy <- sum(decision_tree_pred == df_encoded_test$RiskLevel) / length(df_encoded_test$RiskLevel)
    
    # Store accuracy
    accuracy_values <- c(accuracy_values, accuracy)
  }
}

# Print the best
best_accuracy <- max(accuracy_values, na.rm = TRUE)
cat("Best Accuracy for Decision Tree:", best_accuracy, "\n")
```

**Interpretation:** After tuning the hyperparameters, the best accuracy for the Decision Tree model was ~66%, which is similar to the original model's accuracy, indicating that optimizing hyperparameters did not really improve the model's performance.

#### 3.3 Tuning of hyperparameters for Support Vector on Orignal Dataset

Hyperparameters that can be tuned for SVM:

* Kernel type (e.g., linear, radial basis function)

* Regularization parameter (C)

* Kernel-specific parameters (e.g., gamma for RBF kernel)

* Cost function

### 4. Comparison of models and interpretation

**kNN Model**

* When applied to the simulated dataset, the kNN model exhibits very consistent performance (~69%) and high accuracy (~71%) in the original dataset.

* In both datasets, the precision is great, suggesting that kNN effectively reduces false positives. However, recall is less accurate than precision, indicating that some real positive cases are missed by the model.

* With an F1-score of about 82% for the original dataset and ~79% for the simulated dataset, the F1-score (harmonic mean of precision and recall) shows a good balance between the two datasets.

**Decision Tree Model**

* In the original dataset, the Decision Tree model's accuracy is lower (around 67%) than that of both kNN and SVM. Its remarkable precision (~73%) and comparatively high recall (~78%), however, show that the model is successful in detecting real positives while reducing false negatives.

* Although it is marginally lower than kNN's, the Decision Tree's F1-score (around 75% for the original dataset) shows a fair balance between precision and recall.

* With a better precision and a similar recall, the model exhibits a slight gain in accuracy (~67%) in the simulated dataset, resulting in an improved F1-score of ~81%.

**Support Vector Machine**

* Comparable in terms of overall performance, the SVM model attains the same accuracy as kNN in the original dataset (~71%).

* SVM has an F1-score of about 81%, which is competitive with kNN's F1-score, although having a little greater precision (~83%) and a similar recall value (~78%).

* SVM shows the highest precision (~86%) and maintains a constant accuracy (~69%) in the simulated dataset, indicating that it is highly successful at predicting the positive class. Its recall, however, is somewhat lower than kNN's (~76%), resulting in an F1-score of ~81%, which is extremely comparable to kNN's.

**Summary**

* Accuracy: The Decision Tree model has the lowest accuracy (~67%), while the kNN and SVM models have the same accuracy (~71%) for the original dataset. Every model performs similarly in the simulated dataset.

* Precision: In both datasets, SVM has the highest precision, followed by kNN and Decision Tree. This implies that SVM reduces false positives more effectively.

* Recall: In both datasets, the Decision Tree model has the highest recall, suggesting that it is better at detecting true positives.

* F1-Score: In the original dataset, KNN and SVM perform similarly in terms of F1-score (~81%), however the Decision Tree performs well (~75%) but lags somewhat behind. All of the models had similar F1-scores (~81%) in the simulated dataset.

**Conclusion**

Both SVM and kNN are quite accurate and strike an excellent compromise between recall and accuracy; on the original dataset, kNN performed marginally better than SVM. SVM excels in precision, though, which makes it perfect in situations where reducing false positives is essential.
The Decision Tree model is better at detecting true positives and has a higher recall, although being marginally less accurate. It works especially well when reducing false negatives is the aim.

## Model Tuning and Performance Improvement

### 1. Use of Bagging with Homogenous Learners

By lowering variance, the ensemble technique known as "bagging" (Bootstrap Aggregating) improves accuracy and stability by training numerous instances of the same model on bootstrapped subsets of the dataset. Because it reduces overfitting, it works especially well for decision trees, which are the foundation of Random Forest. Using the randomForest package in R, which trains several decision trees on various data subsets and aggregates their predictions for more reliable results, I applied bagging to a decision tree model to the df_encoded dataframe.

```{r Bagging}
# Decision Tree with Bagging
df_encoded_train$RiskLevel <- as.factor(apply(df_encoded_train[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))
df_encoded_test$RiskLevel <- as.factor(apply(df_encoded_test[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max))

# Apply bagging using randomForest
bagging_model_df_encoded <- randomForest(RiskLevel ~ ., data = df_encoded_train[, !(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))], ntree = 100)

# Make predictions
bagging_pred_df_encoded <- predict(bagging_model_df_encoded, df_encoded_test[, !(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))])

# accuracy
bagging_accuracy_df_encoded <- sum(bagging_pred_df_encoded == df_encoded_test$RiskLevel) / length(df_encoded_test$RiskLevel)
cat("Bagging Accuracy for Decision Tree:", bagging_accuracy_df_encoded, "\n")
```

**Interpretation:** Using the encoded dataset, the bagging model's accuracy was about 85%. In order to increase the robustness and decrease variance of the model, several decision trees were trained on various subsets of the data and their predictions were combined using the randomForest package to execute bagging with decision trees. Compared to a single decision tree model, this improved accuracy shows that bagging improved the model's performance by reducing overfitting and enhancing its capacity for generalization.

### 2. Construction of ensemble model as a function

```{r CosntuctEnsembleModel}
# ensemble function
ensemble_model <- function(df_encoded_train, df_encoded_test, k = 5) {
  # Prepare data
  df_encoded_train_features <- df_encoded_train[, -which(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
  df_encoded_test_features <- df_encoded_test[, -which(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))]
  
  # Prepare labels
  df_encoded_train_labels <- apply(df_encoded_train[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)
  df_encoded_test_labels <- apply(df_encoded_test[, c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid")], 1, which.max)
  
  # kNN model
  knn_pred <- knn(train = df_encoded_train_features, test = df_encoded_test_features, cl = df_encoded_train_labels, k = k)
  
  # Decision Tree model
  df_encoded_train$RiskLevel <- as.factor(df_encoded_train_labels)
  df_encoded_test$RiskLevel <- as.factor(df_encoded_test_labels)
  decision_tree_model <- rpart(RiskLevel ~ ., data = df_encoded_train[, !(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))])
  decision_tree_pred <- predict(decision_tree_model, df_encoded_test[, !(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))], type = "class")
  
  # SVM model
  svm_model <- svm(RiskLevel ~ ., data = df_encoded_train[, !(names(df_encoded_train) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))], 
                   kernel = "radial", cost = 1, probability = TRUE)
  svm_pred <- predict(svm_model, df_encoded_test[, !(names(df_encoded_test) %in% c("RiskLevel_high", "RiskLevel_low", "RiskLevel_mid"))])
  
  # Combine predictions from all three models using majority voting
  combined_pred <- apply(cbind(knn_pred, decision_tree_pred, svm_pred), 1, function(x) {
    # Use the most frequent class as final prediction
    names(sort(table(x), decreasing = TRUE))[1]
  })
  
  # accuracy
  accuracy <- sum(combined_pred == df_encoded_test_labels) / length(df_encoded_test_labels)
  cat("Ensemble Model Accuracy:", accuracy, "\n")
  
  return(combined_pred)
}

# Example
predictions <- ensemble_model(df_encoded_train, df_encoded_test)
```

### 3. Comparison of ensemble model to individual models

The ensemble model achieves the highest accuracy across both datasets, outperforming kNN, Decision Tree, and SVM, which all show lower accuracy scores. This indicates that the ensemble approach provides a more reliable and robust model for classification tasks compared to the individual models.

### 4. Application of ensemble model to make a prediction

The code predicts the first five rows of the test dataset (df_encoded_test) using the trained ensemble model. The first few rows of the chosen test data are shown after predictions are produced using the ensemble_model function and the training data (df_encoded_train).

```{r ApplyEnsemble}
# Pick the first 5 rows
test_rows <- df_encoded_test[1:5, ]

# Run the ensemble model
predictions_for_test_rows <- ensemble_model(df_encoded_train, df_encoded_test)

# view predictions
cat("Predictions for the selected rows:\n")
print(predictions_for_test_rows[1:5])
```




